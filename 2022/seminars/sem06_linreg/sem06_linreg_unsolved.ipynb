{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSHI7j-Q28j3"
   },
   "source": [
    "# Предобработка данных и функции потерь в линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96iNvJn-28j4"
   },
   "source": [
    "## Данные\n",
    "Для демонстраций загрузим набор данных [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/Automobile). В данных присутствуют категориальные, целочисленные и вещественнозначные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u30Ou_XY28j5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_raw = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\", \\\n",
    "                    header=None, na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "U3zLI-Jd28j8",
    "outputId": "84092f79-d9ca-489e-c062-3f80a5a9787c"
   },
   "outputs": [],
   "source": [
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHXo8yny28j_"
   },
   "outputs": [],
   "source": [
    "y = X_raw[25]\n",
    "X_raw = X_raw.drop(25, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RLJ_PH928kC"
   },
   "source": [
    "## Предобработка данных\n",
    "\n",
    "Предобработка данных важна при применении любых методов машинного обучения, а в особенности для линейных моделей. В sklearn предобработку удобно делать с помощью различных модулей [preprocessing](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) или методов библиотеки pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OIYuChq28kH"
   },
   "source": [
    "### Заполнение пропусков\n",
    "В матрице объекты-признаки могут быть пропущенные значения, и это вызовет ошибку при попытке передать такую матрицу в функцию обучения модели или даже предобработки. Если пропусков немного, можно удалить объекты с пропусками из обучающей выборки. Заполнить пропуски можно разными способами:\n",
    "* заполнить средними (mean, median);\n",
    "* предсказывать пропущенные значения по непропущенным.\n",
    "\n",
    "Часто используют первый вариант - он проще. Для заполнения константами можно использовать метод датафрейма `fillna`, для замены средними - класс `impute.SimpleImputer` (в более старых версиях `scikit-learn` - `preprocessing.Imputer`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-mqpQ46y4If",
    "outputId": "b84a8dea-b703-4b35-bdb6-5d25bb1798db"
   },
   "outputs": [],
   "source": [
    "X_raw.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jt8GLu6ly4If",
    "outputId": "03ca79b2-53a4-4501-f7f6-9517c75fc6e0"
   },
   "outputs": [],
   "source": [
    "X_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8xF0_ruy4Ig"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5bbvMK828kH"
   },
   "outputs": [],
   "source": [
    "# для удобства работы с нашим датасетом создаем маску, указывающую на столбцы с категориальными признаками\n",
    "cat_features_mask = (X_raw.dtypes == \"object\").values # категориальные признаки имеют тип \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjYtWWxQ28kK"
   },
   "outputs": [],
   "source": [
    "# для вещественнозначных признаков заполним пропуски средними\n",
    "X_real = X_raw[X_raw.columns[~cat_features_mask]]\n",
    "mis_replacer = SimpleImputer(strategy=\"mean\")\n",
    "X_no_mis_real = pd.DataFrame(data=mis_replacer.fit_transform(X_real), columns=X_real.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для категориальных - пустыми строками\n",
    "X_cat = X_raw[X_raw.columns[cat_features_mask]].fillna(\"\")\n",
    "X_no_mis = pd.concat([X_no_mis_real, X_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "H34gZsTX28kN",
    "outputId": "e59fc36c-9131-4923-fbaa-d41941e265ea"
   },
   "outputs": [],
   "source": [
    "X_no_mis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joT6goKYy4Ih",
    "outputId": "792035e3-4863-4633-fc96-b893be4184e7"
   },
   "outputs": [],
   "source": [
    "X_no_mis.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNoCS3EK28kR"
   },
   "source": [
    "### Преобразование нечисловых признаков\n",
    "Как вы помните, большниство моделей машинного обучения требуют, чтобы на вход функции обучения подавалас матрица состоящая из вещественных чисел. В процессе обучения используются свойства вещественных чисел, в частности, возможность сравнения и применения арифметических операций. Поэтому, даже если формально в матрице объекты-признаки записаны числовые значения, нужно всегда анализировать, можно ли относиться к ним как к числам. \n",
    "\n",
    "__Пример:__ некоторые признаки могут задаваться целочисленными хешами или id (например, id пользователя соц. сети), однако нельзя сложить двух пользователей и получить третьего, исходя из их id (как это может сделать линейная модель).\n",
    "\n",
    "Напоминаем, что для обработки категориальных признаков, часто применяют [one-hot encoding](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features) в результате чего, вместо одного признака добавится $K$ бинарных признаков - по одному на каждое возможное значение исходного признака. В `sklearn` это можно сделать с помощью классов `OneHotEncoder`, но проще использовать функцию `pd.get_dummies`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBmFt92528kS"
   },
   "source": [
    "Следует заметить, что в новой матрице будет очень много нулевых значений. Чтобы не хранить их в памяти, можно задать параметр `OneHotEncoder(sparse=True)` или `pd.get_dummies(sparse=True)`, и метод вернет [разреженную матрицу](http://docs.scipy.org/doc/scipy/reference/sparse.html), в которой хранятся только ненулевые значения. Выполнение некоторых операций с такой матрицей может быть неэффективным, однако большинство методов sklearn умеют работать с разреженными матрицами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZxxhNbj28kS"
   },
   "source": [
    "__Вопрос:__ стоит ли применять one-hot encoding для признаков с большим числом категорий (например, id)? Почему?\n",
    "\n",
    "__Вопрос:__ какая проблема возникнет при применении вышеописанного способа кодирования для обучения линейной регрессии?\n",
    "    \n",
    "Необходимо удалить один из столбцов, созданных для каждого признака. Для этого в get_dummies надо поставить drop_first=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqwMFEqt28ka",
    "outputId": "0f30bded-aedf-4b6a-e829-7d4b7b18624e"
   },
   "outputs": [],
   "source": [
    "X_no_mis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "hLiNNMYz28kc",
    "outputId": "71635d35-f724-43d8-9244-cb83af917b0a"
   },
   "outputs": [],
   "source": [
    "X_dum = pd.get_dummies(X_no_mis, drop_first=True)\n",
    "print(X_dum.shape)\n",
    "X_dum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVJEU31i28kf"
   },
   "source": [
    "Помимо категориальных, преобразования требуют, например, строковые признаки. Их можно превращать в матрицу частот слов [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), матрицу частот буквосочетаний фиксированной длины, можно извлекать другие признаки (например, длина строки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaZ_SxAP28kf"
   },
   "source": [
    "### Масштабирование признаков\n",
    "При начале работы с данными всегда рекомендуется приводить все признаки к одному масштабу.  Это важно по нескольким причинам:\n",
    "* ускорение обучения модели;\n",
    "* улучшение численной устойчивости при работе с матрицей объекты-признаки\n",
    "* для линейных моделей: интерпретация весов при признаках как меры их значимости\n",
    "\n",
    "[Полезная ссылка](https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLCmI77c28kg"
   },
   "source": [
    "Данные можно масштабировать по-разному:\n",
    "\n",
    "- Стандартизация - вычитание среднего из каждого признака и деление на стандартное отклонение (`StandardScaler` в `sklearn`).\n",
    "\n",
    "- Нормализация - вычитание минимума из каждого признака, а затем деление на разницу максимального и минимального значения (`MinMaxScaler` в `sklearn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHFbmKRzy4Im"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNymKr5D28kh"
   },
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "X_real_norm_np = normalizer.fit_transform(X_dum)\n",
    "X = pd.DataFrame(data=X_real_norm_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "3kHPINOO28kk",
    "outputId": "be974402-62de-4387-dc04-6447b504bf92"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbwg7jRv28kn"
   },
   "source": [
    "### Добавление признаков\n",
    "Особенно важным моментом для линейной регрессии является нелинейное преобразование признаков. Это позволяет использовать линейную регрессию для моделирования нелинейных зависимостей. \n",
    "\n",
    "Наиболее популярны следующие преобразования: \n",
    "- полиномиальные признаки (PolynomialFeatures в sklearn)\n",
    "- взятие логарифма\n",
    "- квадратного корня\n",
    "- применение тригонометрических функий.\n",
    "\n",
    "Например, посмотрев на данные, мы можем заметить, что зависимость целевой переменной от шестого признака скорее квадратичная, чем линейная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSL1DWQw28ko"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Bv0qZAP028kr",
    "outputId": "c1fbdef3-0154-4870-d258-1b46177dc96d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[6], y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "In7bi4a728ku",
    "outputId": "d01a472e-d0e9-446a-f011-2944ef6fdb65"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[6]**2, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LLqJaxF28kw"
   },
   "source": [
    "> А для признака номер 13 линеаризовать зависимость получается с помощью функции $\\frac 1 {\\sqrt{x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Ff2MqK_U28kx",
    "outputId": "ca370ede-de10-4c7c-f0cb-5fdf1a7717c9"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[13], y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "6MhgQI3p28kz",
    "outputId": "444da03b-f69c-41f3-98d8-f96105777bc8"
   },
   "outputs": [],
   "source": [
    "plt.scatter(1 / np.sqrt(X[13]), y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6Qy8_i_28k1"
   },
   "source": [
    "__Обратите внимание__: при генерации полиномиальных признаков матрица объекты-признаки может занимать много памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPqAUdTR28k1"
   },
   "source": [
    "## Функции потерь в регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "4nkY6ylA28k2"
   },
   "source": [
    "Функционал качества в задачах обучения с учителем обычно задается в виде суммы по объектам выборки:\n",
    "$$Q(a) = \\frac 1 \\ell \\sum_{i=1}^\\ell L(y_i, a(x_i)),$$\n",
    "где $L(\\cdot, \\cdot)$ - функция потерь, задающая штраф за разницу между предсказанием и истинным значением целевого признака. Свойства функции потерь:\n",
    "* $L(y_i, a(x_i)) \\geqslant 0$;\n",
    "* $L(y_i, y_i) = 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tvTz0GJ28k3"
   },
   "source": [
    "Функционал качества должен в первую очередь отвечать требованиям заказчика, при этом математические свойства функции потерь могут быть неудобны для оптимизации. \n",
    "\n",
    "__Пример:__ если мы не различаем маленькие ошибки (между 0.01 и 0.1 нет особой разницы), но зато не хотим получать большие ошибки, можно использовать следующую функцию потерь:\n",
    "\n",
    "$$L(y_i, a(x_i)) = [| y_i - a(x_i) | < \\varepsilon],$$ $\\varepsilon$ - допустимая разница между предсказанием и фактом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ade-VU28k4"
   },
   "source": [
    "### Среднеквадратичная и средняя абсолютная ошибка\n",
    "Кроме требований заказчика, функционал качества должен учитывать математические особенности модели - например, устойчивость к шумовым объектам. \n",
    "\n",
    "В линейной регрессии Mean Squared Error: $L(y_i, a(x_i)) = (a(x_i) - y_i)^2$ не обладает этим свойством, потому что задает очень большие штрафы за большие отклонения от фактического значения. \n",
    "\n",
    "$$MSE (a, X, Y) = \\sum^L_{i=1}(a(x_i) - y_i)^2$$\n",
    "\n",
    "Рассмотрим это явление на примере. Выберем один признак, от которого целевой признак (имеющий индекс 15 в матрице X) зависит практически линейно. Добавим к выборке два объекта-выброса и посмотрим, как изменится оптимизированная на MSE прямая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPjI7SgJ28k5"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVmJjuUU28k7"
   },
   "outputs": [],
   "source": [
    "X_subset = X[[7, 15]].values\n",
    "X_subset_modified = np.vstack((X_subset, [[1, 90], [2, 50]])) # добавление двух шумовых точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNZJOsJp28k9"
   },
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MSE(X_subset):\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])   # визуализируем точки\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_subset[:, 0][:, np.newaxis], X_subset[:, 1])  # вычислим веса линейной модели\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    line = lr.predict(grid[:, np.newaxis])\n",
    "    plt.plot(grid, line)   # визуализируем прямую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "EurNOGcA28k_",
    "outputId": "a0a4b098-838b-4f81-9796-b6fb5f1d80eb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter_points_and_plot_line_MSE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter_points_and_plot_line_MSE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6JR5Gxq8ZcZ"
   },
   "source": [
    "**Задание:** Реализуйте функцию для подсчета MSE с использованием numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1mp3T5y844J",
    "outputId": "8bec51dd-6f89-4b1a-9653-9964ca0e4c34"
   },
   "outputs": [],
   "source": [
    "def MSE(y: np.array, y_pred: np.array):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "\n",
    "a = np.array([11,20,19,17,10])\n",
    "pred = np.array([12,18,19.5,18,9])\n",
    "mse = MSE(y=a, y_pred=pred)\n",
    "print(\"The Mean Square Error is: \" , mse)\n",
    "assert mse == 1.45 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoNn7V3VAxH7"
   },
   "source": [
    "Среднеквадратичная ошибка подходит для сравнения двух моделей или для контроля качества во время обучения. Из-за того, разница возводится в квадрат - сложно дать этому числу интерпретацию. Для лучшей интерпретации используется Root Mean Square Error (RMSE). Таким образом, если MSE показывает разницу в квадратных единицах, значение RMSE сохранится в исходных. \n",
    "\n",
    "$$RMSE (a, X, Y) = \\sqrt{MSE (a, X)} = \\sqrt{ \\sum^L_{i=1}(a(x_i) - y_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2R6urCMCeN5"
   },
   "source": [
    "**Задание:** Реализуйте функцию для подсчета RMSE с использованием numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IowhU6p1Cj47",
    "outputId": "4c63cf61-4097-4488-f889-8a8c8eb777c6"
   },
   "outputs": [],
   "source": [
    "def RMSE(y, y_pred):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "\n",
    "rmse = RMSE(y=a, y_pred=pred)\n",
    "print(\"The Root Mean Square Error is: \" , rmse)\n",
    "assert rmse == 1.2041594578792296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3eqYonVJd8a"
   },
   "source": [
    "Коэффициент детерминации $R^2$ показывает долю дисперсии в целевой переменной, которая обьяснена зависимыми переменными. $R^2$ можно интерпретировать как некоторого рода нормированное MSE.\n",
    "\n",
    "$$R^2(a, X, Y) = 1 - \\frac {\\sum^L_{i=1}(a(x_i) - y_i)^2}{\\sum^L_{i=1}(y_i - \\bar{y})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgfsEt5DLbQW"
   },
   "source": [
    "**Задание:** реализуйте функцию для вычисления $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KK3o7GozLjkV"
   },
   "outputs": [],
   "source": [
    "def R_squared(y, y_pred):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "r_squared = R_squared(y=a, y_pred=pred)\n",
    "print('The R2 is:', r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa7c8WRk28lC"
   },
   "source": [
    "Из-за того, что мы учитываем квадрат отклонения - шумовые объекты могут сильно изменить наклон прямой. Поэтому в качестве альтернативы MSE можно использовать Mean Absolute Error: $L(y_i, a(x_i)) = |a(x_i) - y_i|$.\n",
    "\n",
    "$$MAE(a, X, Y) = \\frac {1}{L} \\sum^L_{i=1}|a(x_i) - y_i|$$\n",
    "\n",
    "Теперь обучим регрессию, оптимизируя MAE. В `sklearn` такая регрессия не реализована, но можно использовать модуль `statsmodels` - более формально, необходимая модель может быть получена с помощью обучения квантильной регрессии с параметром `q=0.5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jqHvxqXDt6q"
   },
   "source": [
    "**Задание:** Реализуйте функцию для подсчета MAE с использованием numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eo-0TW82DzPw",
    "outputId": "f4e36fd7-9184-4ebb-e7f6-79e48d5c9124"
   },
   "outputs": [],
   "source": [
    "def MAE(y, y_pred):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "\n",
    "mae = MAE(y=a, y_pred=pred)\n",
    "print(\"The Mean Absolute Error is: \" , mae)\n",
    "assert mae == 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KRvgVyVy4Iq"
   },
   "source": [
    "!pip install --user git+https://github.com/statsmodels/statsmodels # (если не работает импортирование библиотек ниже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PL2zqH8x28lD"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFTTYeqY28lF"
   },
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MAE(X_subset):\n",
    "    # задаем зависимость переменной f15 от переменной f7 и передаем данные\n",
    "    mod = smf.quantreg('f15 ~ f7', pd.DataFrame(data=X_subset, columns=[\"f7\", \"f15\"]))\n",
    "    res = mod.fit(q=0.5)\n",
    "    \n",
    "    # визуализируем точки\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    \n",
    "    # визуализируем прямую\n",
    "    plt.plot(grid, grid * res.params[\"f7\"] + res.params[\"Intercept\"])\n",
    "    return mod, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ie_4TNdc28lH",
    "outputId": "85bcab8b-0876-4f52-98a7-87dc18beecdd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWlsyGfu28lK"
   },
   "source": [
    "Прямая практически не изменила направление из-за выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2doEVqJ28lL"
   },
   "source": [
    "Попробуем добавить больше шумовых объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdDGJBER28lM"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "X_subset_modified_twice = np.vstack((X_subset_modified, np.random.randint(5, size=60).reshape(-1, 2)*[1, 30])) # добавление 30 шумовых точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "McWJOOlN28lO",
    "outputId": "c44d54b7-7cda-4650-cf53-257573a82815"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified_twice)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCq7zu_K28lQ"
   },
   "source": [
    "Под таким количеством выбросов, изменилась даже регрессия над MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PMB5CGj28lR"
   },
   "source": [
    "Рассмотрим некоторые свойства MSE и MAE.\n",
    "\n",
    "Допустим алгоритм возвращает константное предсказание: $a(x) = C, C \\in R$. В качестве примера такого алгоритма можно представить предсказание прибыли в январе константой, равной средней прибыли за январь всех предыдущих лет работы.\n",
    "\n",
    "__Задача.__ Найдите $C$, минимизирующий среднеквадратичную ошибку.\n",
    "\n",
    "__Задача.__ Найдите $C$, минимизирующий среднюю абсолютную ошибку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7lxcAGx28lR"
   },
   "source": [
    "Поскольку средняя абсолютная ошибка не является дифференцируемой по $w$ функцией, оптимизировать ее напрямую методом градиентного спуска не удастся. Для этого используются [субградиентные](https://ru.wikipedia.org/wiki/Субдифференциал) (что в почти не меняет процедуры спуска, только вместо градиента берется один из субградиентов) или другие методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMkNLdXE28lS"
   },
   "source": [
    "### Huber Loss\n",
    "Иногда используют \"гибрид\" MAE и MSE, который, как и MAE, устойчив к шумовым объектам, и как и MSE, мало штрафует малые отклонения от фактического значения целевого признака - Huber Loss:\n",
    "$$L_i(y_i, a(x_i)) = \\phi_\\varepsilon(a(x_i) - y_i)$$\n",
    "$$\\phi_\\varepsilon(z) = \\begin{cases} \\frac 1 2 z^2, - \\varepsilon < z < \\varepsilon, \\\\\\varepsilon (|z| - \\frac 1 2 \\varepsilon), иначе \\\\ \\end{cases}$$\n",
    "\n",
    "Можно проверить, что у этой функции существует непрерывная первая проиводная во всех точках.\n",
    "\n",
    "Оптимизация Huber Loss реализована в sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63HdJ0fl28lT"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5_lQyA1Hz2l"
   },
   "source": [
    "**Задание:** реализуйте функцию потерь Хьюбера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyTaEVslFGb5",
    "outputId": "9223c84d-8e2a-438e-c0bd-35aa797dd8e7"
   },
   "outputs": [],
   "source": [
    "def Huber(y, y_pred):\n",
    "    #YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "huber = Huber(y=a, y_pred=pred)\n",
    "print(\"The Huber Loss is:\", huber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00WIecdEGqE7"
   },
   "source": [
    "### Mean Squared Logarifmic Erorr (MSLE)\n",
    "\n",
    "Данная функция потерь применяется в случаях, когда лучше получать заниженные прогнозы, нежели завышенные.\n",
    "\n",
    "Важное примечание: из-за присутствия логарифма в формуле **целевая переменная должна быть неотрицательной!**. Единицу добавляем, чтобы случайно не получить логарифм нуля.\n",
    "\n",
    "$$L_i(a, X_i, Y_i) = (\\log(a(x_i)+1) - \\log(y_i+1))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDbvxTRyHyRB"
   },
   "source": [
    "**Задание:** реализуйте MSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzpzqKvLINLo"
   },
   "outputs": [],
   "source": [
    "def MSLE(y, y_pred):\n",
    "    #YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "msle = MSLE(y=a, y_pred=pred)\n",
    "print(\"The Mean Squared Logarifmic Error is:\", msle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5Yy3Ze228lV"
   },
   "source": [
    "### Quantile Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vBaAgJJ28lW"
   },
   "source": [
    "В некоторых задачах штраф за ошибку зависит не только от величины абсолютного отклонения от фактического значения, но и от знака этого отклонения. Например, лучше предсказать спрос больше, чем будет по факту, чем меньше, потому что во втором случае будет потеряна прибыль. В этом случае используется квантильная регрессия со следующей функцией потерь:\n",
    "$$L_i(y_i, a(x_i)) = \\rho_\\tau(y_i - x_i^T w),$$\n",
    "$$\\rho_\\tau(z) = \\begin{cases} \\tau z, \\quad z > 0, \\\\ (\\tau - 1) z, \\quad z \\leqslant 0 \\end{cases}$$\n",
    "Параметр $\\tau \\in (0, 1)$ влияет на то, насколько различаются штрафы за положительную и отрицательную разницу.\n",
    "\n",
    "Изобразим график квантильной функции потерь вместе с некоторыми другими рассмотренными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "LZvF9yTL28lW",
    "outputId": "124dc493-7f6c-486d-9adf-2379c3d2ef6e"
   },
   "outputs": [],
   "source": [
    "grid = np.linspace(-3, 3, 100)\n",
    "quantile_tau = 0.2\n",
    "mse_loss = grid ** 2\n",
    "rmse_loss = np.sqrt(mse_loss)\n",
    "mae_loss = np.abs(grid)\n",
    "huber_loss = 0.5 * mse_loss * (grid >= -1) * (grid <= 1) + (mae_loss - 0.5) * (grid < -1) + (mae_loss - 0.5)  * (grid > 1)\n",
    "quantile_loss = quantile_tau * grid * (grid > 0) + (quantile_tau - 1) * grid * (grid <= 0)\n",
    "plt.plot(grid, mae_loss, label=\"Absolute Loss\")\n",
    "plt.plot(grid, mse_loss, label=\"Quadratic Loss\")\n",
    "plt.plot(grid, rmse_loss, label=\"Root Quadratic Loss\")\n",
    "plt.plot(grid, huber_loss, label=\"Huber Loss\")\n",
    "plt.plot(grid, quantile_loss, label=\"Quantile Loss\")\n",
    "plt.xlabel(\"$y_i - a(x_i)$\")\n",
    "plt.ylabel(\"$L(y_i, a(x_i))$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKsQQ-I728lY"
   },
   "source": [
    "__Задача.__ Укажите параметр $\\tau$, при котором обучение квантильной регрессии равносильно оптимизации MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0dnqaQa28lZ"
   },
   "source": [
    "Проследим наклон прямой в нашей одномерной задаче регрессии при изменении $\\tau$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "rq4LwwR728lZ",
    "outputId": "09855fa8-123a-48cd-dc8b-6daf9f82c64e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[7], y)\n",
    "\n",
    "grid = np.linspace(0, 2, 100)\n",
    "dat = pd.DataFrame({\"x\":X[7], \"y\":y})\n",
    "mod = smf.quantreg('y ~ x', dat)\n",
    "\n",
    "for q in np.arange(0.1, 1, 0.1):\n",
    "    res = mod.fit(q=q)\n",
    "    plt.plot(grid, grid * res.params[\"x\"] + res.params[\"Intercept\"], linewidth=0.5, label=\"q = \"+str(q))\n",
    "\n",
    "plt.legend(loc=(1.1, 0.1))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aefAEVx7OiAR"
   },
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2jmXcciOl-K"
   },
   "source": [
    "Мы поработаем с данными о сообществах в США. Описание датасета:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/communities+and+crime\n",
    "\n",
    "Датасет на кэггле (в формате .csv):\n",
    "\n",
    "https://www.kaggle.com/kkanda/communities%20and%20crime%20unnormalized%20data%20set\n",
    "\n",
    "Будем предсказывать количество насильственных преступлений относительно численности населения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3lmXNVFOx0G"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRft8CJyO1z8"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('crimedata.csv', na_values=[\"?\"])\n",
    "\n",
    "# оставим лишь нужные колонки\n",
    "requiredColumns = [5, 6] + list(range(11,26)) + list(range(32, 103)) + [145]\n",
    "data = data[data.columns[requiredColumns]]\n",
    "\n",
    "# некоторые значения целевой переменной пропущены\n",
    "X = data.loc[data['ViolentCrimesPerPop'].notnull(), :].drop('ViolentCrimesPerPop', axis=1)\n",
    "y = data['ViolentCrimesPerPop'][X.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCxXAdVtOiw4"
   },
   "source": [
    "### 1 Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw3DZ8zzPRuB"
   },
   "source": [
    "Обучим линейную регрессию и выведем качество по метрике MSE на обучающей и тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntYfZTzkQRAC"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test))))\n",
    "\n",
    "# Выведите ниже качество на обучении и тесте, рассчитаное с использованием функции\n",
    "# MSE(), написанной вами ранее\n",
    "# Сравните результаты\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd44Omp9TtcU"
   },
   "source": [
    "Популярным решением для регрессионных моделей является **регуляризация**.\n",
    "\n",
    "Во время оптимизации линейной регрессии, веса при переменных могут получится большими в абсолютных значениях. Это не очень хорошо, поскольку классификатор будет чувствителен к крайне маленьким изменениям в признаках объекта, а значит, переобучен.\n",
    "\n",
    "Для решения проблемы к функционалу ошибки добавляют так называемсый регуляризатор, который \"штрафует\" модель за слишком большую норму вектора весов:\n",
    "\n",
    "\n",
    "$$Q\\alpha(w) = Q(w) + \\alpha R(w)$$ \n",
    "\n",
    "где $R(w)$ - регуляризатор\n",
    "\n",
    "Наиболее распространенными являются L1 и L2 регуляризаторы\n",
    "$$L1: R(w) = ||w||_1 = \\sum^d_i w_i^2$$\n",
    "\n",
    "$$L2: R(w) = ||w||_2 = \\sum^d_i |w_i|$$\n",
    "\n",
    "Давайте применим каждый из них к нашей задаче и посмотрим на изменение в результатах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-Lpzpe0QcJF"
   },
   "source": [
    "В качестве метода регуляризации используем Ridge ($L_2$-регуляризация)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RT8QZldbPqFr",
    "outputId": "126eb557-1c3d-4bdb-fe05-a4eb0adc1d76"
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzcwQ0T5QkRJ"
   },
   "source": [
    "### 2 Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjOT_WBfQnWX"
   },
   "source": [
    "Попробуем MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zedtNiBBQhOl"
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(data=sc.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(data=sc.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrldySniQ6jR"
   },
   "source": [
    "**Задание:** Напишите код обучения линейной регресии на масштабированных признаках и выведите ошибку на обучающей и валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyoESXkkRQA1"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkbwYrUdRSYR"
   },
   "source": [
    "**Задание:** проделайте аналогичную работу, добавив Ridge регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDELVx5FRh1F"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK7GsUVORnbG"
   },
   "source": [
    "### 3. High/low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1Obs0jBRpsw"
   },
   "source": [
    "Полезны ли признаки, имеющие высокую дисперсию? А низкую?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDlYyvBsRnwb",
    "outputId": "99a5078b-8d5c-4079-b130-c096ac8c41d4"
   },
   "outputs": [],
   "source": [
    "features_variance = X_train_scaled.var().sort_values(ascending=False)\n",
    "features_variance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qW04UvAbRyhG"
   },
   "source": [
    "Попробуем удалить признаки с самой низкой дисперсией и посмотреть, как изменится качество. В sklearn есть специальный инструмент для такого наивного отбора признаков. Стоит ли нормализовать перед этим признаки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StGlZfbeRsec",
    "outputId": "ef18c63f-14c6-4d84-98f7-ccc92e707dbe"
   },
   "outputs": [],
   "source": [
    "# можно убрать все признаки, дисперсия которых меньше заданного значения\n",
    "vs_transformer = VarianceThreshold(0.01)\n",
    "\n",
    "X_train_var = pd.DataFrame(data=vs_transformer.fit_transform(X_train_scaled), columns=X_train_scaled.columns[vs_transformer.get_support()])\n",
    "X_test_var = pd.DataFrame(data=vs_transformer.transform(X_test_scaled), columns=X_test_scaled.columns[vs_transformer.get_support()])\n",
    "\n",
    "X_train_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z60-yCrwR2rG",
    "outputId": "b4294aec-3712-41f5-8170-f924cfcd155b"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_var,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_var))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_var))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXlTH65eR5hs",
    "outputId": "5c6ce1a9-aa30-4b95-86fd-0ecda5f9791e"
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_var,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_var))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_var))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-tIhMytR9KO"
   },
   "source": [
    "### 4 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmyRffiqR9lz"
   },
   "source": [
    "Можно выбрать k признаков, которые дают наиболее высокие значения корреляции с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxgWrpvVR7_H"
   },
   "outputs": [],
   "source": [
    "# Выбираем 15 лучших признаков\n",
    "sb = SelectKBest(f_regression, k=15)\n",
    "\n",
    "X_train_kbest = pd.DataFrame(data=sb.fit_transform(X_train_var, y_train), columns=X_train_var.columns[sb.get_support()])\n",
    "X_test_kbest = pd.DataFrame(data=sb.transform(X_test_var), columns=X_test_var.columns[sb.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05_0s6Y0SPYp",
    "outputId": "4d2beea0-bc84-42ad-f239-3002fb223ef9"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_kbest,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_kbest))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_kbest))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brBAuwBHSSXA",
    "outputId": "3ea8e8b3-4be0-4071-9a42-50453af4d5bc"
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_kbest,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_kbest))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_kbest))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1oWr6MASWck"
   },
   "source": [
    "А можно выбрать самые значимые признаки с точки зрения регрессии с $L_1$-регуляризацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R7rsWRvSVFA",
    "outputId": "be80b01d-4ccb-4231-8f99-c36459d30215"
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(5.0)\n",
    "l1_select = SelectFromModel(lasso)\n",
    "\n",
    "X_train_l1 = pd.DataFrame(data=l1_select.fit_transform(X_train_var, y_train), columns=X_train_var.columns[l1_select.get_support()])\n",
    "X_test_l1 = pd.DataFrame(data=l1_select.transform(X_test_var), columns=X_test_var.columns[l1_select.get_support()])\n",
    "\n",
    "X_train_l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VO2rVJfSikj",
    "outputId": "c2194e3b-8341-40cf-c0cd-a9616df38c72"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_l1,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_l1))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_l1))))\n",
    "\n",
    "ridge = Ridge(5.0).fit(X_train_l1,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_l1))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_l1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlvrsWnsSqJ2"
   },
   "source": [
    "### 5 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vD3_WwmwSspu"
   },
   "source": [
    "А можно сделать все вышеописанное сразу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6SHSnsUSpJU",
    "outputId": "ae41e7cd-bcdd-43b0-844e-b830c2b8821a"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('variance', VarianceThreshold(0.01)),\n",
    "    ('selection', SelectFromModel(Lasso(5.0))),\n",
    "    ('regressor', Ridge(5.0))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R84AM0WISw1i",
    "outputId": "7ab81bbe-a396-4eed-bb17-01db96062e6e"
   },
   "outputs": [],
   "source": [
    "print (\"Train: {}\".format(mean_squared_error(y_train, pipe.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, pipe.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN1m9tlWS2zh"
   },
   "source": [
    "Можно также настраивать параметры с помощью `GridSearch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fqn1f7qS2Kt",
    "outputId": "b07efc95-76ec-4699-dda9-9b80a2293f9d"
   },
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4m5LRWZgS_3e",
    "outputId": "7772273e-c44b-4298-e513-abd490a91ac4"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'variance__threshold': [0.005, 0.0075, 0.009, 0.01, 0.011, 0.012],\n",
    "    'selection__estimator__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "    'regressor__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0]\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, param_grid, iid=False, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G98XFUynTGJV",
    "outputId": "052f7b76-a35a-4c9d-83f2-19b69f9b1267"
   },
   "outputs": [],
   "source": [
    "pipe_best = grid_search.best_estimator_\n",
    "pipe_best.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Uhgfp_WTJvD",
    "outputId": "4206a94b-01cb-4429-ed67-6f57ed016262"
   },
   "outputs": [],
   "source": [
    "pipe_best.fit(X_train, y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, pipe_best.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, pipe_best.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0ir6jSdUGfc"
   },
   "source": [
    "### Источники\n",
    "[Лекции Евгения Соколова в рамках курса МО-1](https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/lecture-notes/)\n",
    "\n",
    "[Семинар Евгения Ковалева в рамках данного курса в 2019 году](https://github.com/KovalevEvgeny/minor2019-iad2/blob/master/sem05_linreg/sem05_linear_regression.ipynb)\n",
    "\n",
    "[Семинар Евгения Ковалева в рамках данного курса в 2020 году](https://github.com/KovalevEvgeny/minor2020-iad4/blob/master/sem06_linreg/sem06_linreg.ipynb)\n",
    "\n",
    "[Семинар Евгения Ковалева, посвященный отбору признаков и регуляризации (2020)](https://github.com/KovalevEvgeny/minor2019-iad2/tree/master/sem06_feature_selection_regularization)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "sem06_linreg_unsolved.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
