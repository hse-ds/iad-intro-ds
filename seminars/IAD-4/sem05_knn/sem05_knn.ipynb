{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что такое алгоритм kNN?\n",
    "\n",
    "Начнем с введения некоторых определений и обозначений.\n",
    "\n",
    "* Мы будем использовать $x$ для обозначения вектора признаков (или атрибутов) объекта.\n",
    "* Под $y$ мы будем подразумевать метку или класс, который мы пытаемся предсказать.\n",
    "\n",
    "KNN входит в число **supervised** алгоритмов или алгоритмов \"обучения с учителем\".\n",
    "Это означает, что нам предоставляется размеченный набор данных, для которого известны соответствия между наблюдениями $(x, y)$. Целью является на основе предоставляемой выборки найти связь между $x$ и $y$, чтобы восстановить функцию $h: X \\rightarrow Y$. Имея такую функцию, мы можем предсказать $y$ по имеющемуся наблюдению $x$.\n",
    "\n",
    "Обучение KNN заключается в запоминании экземпляров обучающей выборки, которые впоследствии используются как «знание» для фазы прогнозирования. Конкретно это означает, что только когда запрос в нашу базу данных сделан (т.е. когда мы просим KNN предсказать метку с учетом ввода), алгоритм будет использовать экземпляры обучения, чтобы выдать ответ.\n",
    "\n",
    "Нужно понимать, что фаза обучения, заключающаяся в запоминании объектов выборки не является дорогостоящей по времени. Однако этого нельзя сказать о фазе тестирования. Если база обучения достаточно большая, осуществление поиска по ней достаточно дорогостоящий процесс.\n",
    "\n",
    "### Как работает kNN?\n",
    "\n",
    "В случае классификации алгоритм K-ближайших соседей по существу сводится к подсчету большинства голосов между K наиболее похожими экземплярами для данного тестового экземпляра. Сходство экземпляров определяется по расстоянию между двумя точками данных. Популярным выбором является евклидово расстояние, но также можно использовать другие меры близости в зависимости от ситуации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "class0 = np.random.normal(4, 2, size=(50, 2))\n",
    "class1 = np.random.normal(2, 1.5, size=(50, 2))\n",
    "data = np.vstack((class0, class1))\n",
    "target = np.hstack((np.zeros(len(class0)), np.ones(len(class1)))).astype(int)\n",
    "plt.scatter(data[:, 0], data[:, 1], c=target, s=100, cmap='winter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(X=data, y=target, clf=knn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем поменять параметр `n_neighbors` у классификатора kNN. Что получается, когда соседей очень мало? Когда очень много? Как меняется граница между классами?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))\n",
    "\n",
    "for i, n_neighbors in enumerate([1, 3, 5, 7, 9, 15, 25, 51, 99]):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(data, target)\n",
    "    ax_curr = ax[i // 3, i % 3]\n",
    "    ax_curr.set_title('n_neighbors = {}'.format(n_neighbors))\n",
    "    ax_curr.axis('off')\n",
    "    plot_decision_regions(X=data, y=target, clf=knn, ax=ax_curr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Что произойдет, если выборка несбалансирована, а значение `n_neighors` равно числу объектов выборки?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2tCO10RQu36"
   },
   "source": [
    "Перейдем к применению kNN на практике с помощью библиотеки scikit-learn. Эта библиотека включает в себя множество алгоритмов, несколько тестовых наборов данных, функции для подсчета метрик и подбора параметров.\n",
    "\n",
    "---\n",
    "\n",
    "Scikit-learn появился как проект David Cournapeau на Google Summer of Code. Позднее к проекту присоединились другие разработчики, и первый релиз библиотеки состоялся 1 февраля 2010 года. Она быстро стала популярной засчет большого количества алгоритмов и простоты использования. Библиотека sklearn полезна для экспериментов, написания быстрых прототипов, участия в соревнованиях по анализу данных и во множестве других приложения. В тоже время, для промышленных проектов она может не подходить ввиду неоптимизированного кода и выбранного языка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWjobx8iS30c"
   },
   "source": [
    "Рассмотрим стандартный датасет c помощью функции `load_boston`. Датасет содержит информацию о ценах на квартиры и какие-то параметры квартиры: близость к реке, криминогенная обстановка в районе и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSRs-70m9bo4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0LunugoX90W_",
    "outputId": "04f953af-58b5-46fe-df54-93cef2cfb533"
   },
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZeAdTFcd99s2"
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "D99aucKZTl9l",
    "outputId": "2db2a23c-8e8d-4745-e62b-c461f424d7f5"
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQmDZ97ClMfd"
   },
   "source": [
    "Посмотрим на наши данные. Давайте построим  график того, как цена зависит цена от криминогенной обстановки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "M6om5C9Rlfiq",
    "outputId": "f6d77bee-b52e-4cc0-ece6-1631d9c67b10"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X['CRIM'], y)\n",
    "plt.xlabel('Crime rate')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Kov6hgVl7Za"
   },
   "source": [
    "Как мы видим, дорогие квартиры находятся в районах с низким уровнем преступности. Что, в принципе, закономерно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCyzTCzC-RPX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0-pFImWNpVX"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQ7y2N9EWwF7"
   },
   "source": [
    "Импортируем алгоритм knn из sklearn. Работа с алгоритмами машинного обучения в библиотеке состоит из трех этапов.\n",
    "\n",
    "\n",
    "\n",
    "1.   Создание объекта, который будет реализовывать алгоритм.\n",
    "2.   Вызов `fit`: обучение модели на тренировочной подвыборке\n",
    "3.   Вызов `predict`: получение предсказаний на тестовой выборке\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdXI0BlZ-MaH"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2vJhFTPM-_hw",
    "outputId": "838e8143-2182-4150-cdcd-1ebf5f1a5655"
   },
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0F-71xehNKQm"
   },
   "outputs": [],
   "source": [
    "predictions = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QEqvxycJYncL"
   },
   "source": [
    "Отлично! Мы получили предсказания. Посчитаем метрику - соответствующая функция есть в scikit-learn. Будем считать среднеквадратичную ошибку, так как мы решаем задачу регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ydpg9MH9NOTD"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vyrD9P7gNrpl"
   },
   "source": [
    "Давайте попробуем сделать лучше. У нашего алгоритма есть множество гиперпараметров: количество соседей, параметры метрики и веса. Запустим поиск по сетке гиперараметров, алгоритм переберет все возможные комбинации, посчитает метрику для каждого набора и выдаст лучший набор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFJ33oeANw8Y"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_searcher = GridSearchCV(\n",
    "    KNeighborsRegressor(),\n",
    "    param_grid={\n",
    "        'n_neighbors': range(1, 40, 2),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2, 3]\n",
    "    },\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4e9XpFCdeeMe"
   },
   "source": [
    "Параметр `cv=5` говорит, что во время поиска оптимальных парамертов будет использоваться кросс-валидация с 5 фолдами. Давайте вспомним, что это такое: \n",
    "\n",
    "![alt text](https://miro.medium.com/max/700/1*rgba1BIOUys7wQcXcL4U5A.png)\n",
    "\n",
    "*Source: https://towardsdatascience.com/cross-validation-explained-evaluating-estimator-performance-e51e5430ff85*\n",
    "\n",
    "В нашем случае, выборка будет разделена на 5 частей, и на каждой из 5 итераций часть данных будет становиться тестовой выборкой, а другая часть - обучающей. Посчитав метрики на каждой итерации, мы сможем усреднить их в конце и получить достаточно точную оценку качества нашего алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASqSEMsCPBD0"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "grid_searcher.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWdAzpvXayNe"
   },
   "source": [
    "Посмотрим на предсказание лучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQyWWnrSONPo"
   },
   "outputs": [],
   "source": [
    "best_predictions = grid_searcher.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nDV8_O3zPbN-",
    "outputId": "72d786bc-edc1-480c-ab7f-8c06cefefde2"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, best_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на лучшие гиперпараметры, найденные по кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pnvwj0dBbFEm"
   },
   "source": [
    "Давайте посмотрим на качество алгоритма в зависимости от количества соседей и от типа алгоритма (с разными весами и весами, обратно пропорциональными расстоянию). Качество будем оценивать с помощью кросс-валидации на обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3mbvV2VOOxF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "neighbors = np.arange(1, 101, 2)\n",
    "\n",
    "scores_uni = []\n",
    "scores_dis = []\n",
    "\n",
    "for k in neighbors:\n",
    "    knn_uniform = KNeighborsRegressor(n_neighbors=k, weights='uniform')\n",
    "    knn_distance = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    scores_uni.append(-cross_val_score(knn_uniform, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "    scores_dis.append(-cross_val_score(knn_distance, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "    \n",
    "plt.plot(neighbors, scores_uni, label='uniform')\n",
    "plt.plot(neighbors, scores_dis, label='distance')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zLZbcalhdhuP"
   },
   "source": [
    "Помимо готовых датасетов, в библиотеке sklearn можно найти функции для генерации искусственных данных. Давайте сгенерируем датасет для классификации и визуализируем его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8IFS3Vrj6iG"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=200, noise=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "FS5bpbacfrpN",
    "outputId": "5ac2de23-7de8-4a22-a14c-f7ccc32a80e2"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap='winter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания для самостоятельной работы.\n",
    "\n",
    "1. https://nbviewer.jupyter.org/github/shestakoff/minor_da_2017/blob/master/colloc_knn.ipynb\n",
    "2. Визуализируйте границу между классами для датасета `moons` для разного числа соседей и разных типов kNN (гиперпараметр `weights`). Как меняется граница в зависимости от числа соседей и типа алгоритма?\n",
    "3. Влияет ли масштабирование на результат работы kNN? Примените два способа масштабирования к датасету `boston` - `MinMaxScaler` и `StandardScaler`. Как меняется качество алгоритма? Найдите оптимальные параметры."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sklearn-Screencast.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
